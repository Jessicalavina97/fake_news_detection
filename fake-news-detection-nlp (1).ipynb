{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection Model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Tensorflow libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from gensim.models import Word2Vec # Word2Vec module\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, remove_stopwords, strip_numeric, stem_text\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "submission_data = pd.read_csv(\"sample submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>3</td>\n",
       "      <td>After (Jeb) Bushs two terms in office, Florida...</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>2</td>\n",
       "      <td>There have been more than 300 mass shootings i...</td>\n",
       "      <td>guns,public-safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>1</td>\n",
       "      <td>There were fewer civilian casualties in Cambod...</td>\n",
       "      <td>foreign-policy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                               Text  \\\n",
       "926        3  After (Jeb) Bushs two terms in office, Florida...   \n",
       "9339       2  There have been more than 300 mass shootings i...   \n",
       "9447       1  There were fewer civilian casualties in Cambod...   \n",
       "\n",
       "                Text_Tag  \n",
       "926            education  \n",
       "9339  guns,public-safety  \n",
       "9447      foreign-policy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data from training data\n",
    "train_data.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Labels    10240 non-null  int64 \n",
      " 1   Text      10240 non-null  object\n",
      " 2   Text_Tag  10238 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 240.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>2</td>\n",
       "      <td>On abortion</td>\n",
       "      <td>abortion,candidates-biography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1</td>\n",
       "      <td>On support for gay marriage.</td>\n",
       "      <td>civil-rights,families,gays-and-lesbians,marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>1</td>\n",
       "      <td>Obama says Iran is a 'tiny' country, 'doesn't ...</td>\n",
       "      <td>foreign-policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>1</td>\n",
       "      <td>On repealing the 17th Amendment</td>\n",
       "      <td>debates,elections,states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>3</td>\n",
       "      <td>Four balanced budgets in a row, with no new ta...</td>\n",
       "      <td>job-accomplishments,jobs,state-budget,state-fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>1</td>\n",
       "      <td>On a cap-and-trade plan.</td>\n",
       "      <td>cap-and-trade,climate-change,environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>1</td>\n",
       "      <td>On the Trans-Pacific Partnership.</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>2</td>\n",
       "      <td>During Sherrod Browns past decade as a D.C. po...</td>\n",
       "      <td>economy,job-accomplishments,jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>1</td>\n",
       "      <td>On changing the rules for filibusters on presi...</td>\n",
       "      <td>congressional-rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6759</th>\n",
       "      <td>2</td>\n",
       "      <td>On torture.</td>\n",
       "      <td>human-rights,terrorism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>1</td>\n",
       "      <td>On support for the Export-Import Bank</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7248</th>\n",
       "      <td>2</td>\n",
       "      <td>On the status of illegal immigrants</td>\n",
       "      <td>immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>5</td>\n",
       "      <td>Six justices on the U.S. Supreme Court have be...</td>\n",
       "      <td>congress,legal-issues,supreme-court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>5</td>\n",
       "      <td>Says Mitt Romney flip-flopped on abortion.</td>\n",
       "      <td>abortion,message-machine-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9400</th>\n",
       "      <td>2</td>\n",
       "      <td>Twenty million Americans are out of work.</td>\n",
       "      <td>jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642</th>\n",
       "      <td>1</td>\n",
       "      <td>On changing the rules for filibusters on presi...</td>\n",
       "      <td>congressional-rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>0</td>\n",
       "      <td>Some 20,000 Delphi salaried retirees lost up t...</td>\n",
       "      <td>corporations,economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                               Text  \\\n",
       "1014       2                                        On abortion   \n",
       "1814       1                       On support for gay marriage.   \n",
       "1846       1  Obama says Iran is a 'tiny' country, 'doesn't ...   \n",
       "2697       1                    On repealing the 17th Amendment   \n",
       "2846       3  Four balanced budgets in a row, with no new ta...   \n",
       "3256       1                           On a cap-and-trade plan.   \n",
       "4386       1                  On the Trans-Pacific Partnership.   \n",
       "4839       2  During Sherrod Browns past decade as a D.C. po...   \n",
       "4940       1  On changing the rules for filibusters on presi...   \n",
       "6759       2                                        On torture.   \n",
       "6784       1              On support for the Export-Import Bank   \n",
       "7248       2                On the status of illegal immigrants   \n",
       "7647       5  Six justices on the U.S. Supreme Court have be...   \n",
       "8906       5         Says Mitt Romney flip-flopped on abortion.   \n",
       "9400       2          Twenty million Americans are out of work.   \n",
       "9642       1  On changing the rules for filibusters on presi...   \n",
       "9750       0  Some 20,000 Delphi salaried retirees lost up t...   \n",
       "\n",
       "                                               Text_Tag  \n",
       "1014                      abortion,candidates-biography  \n",
       "1814   civil-rights,families,gays-and-lesbians,marriage  \n",
       "1846                                     foreign-policy  \n",
       "2697                           debates,elections,states  \n",
       "2846  job-accomplishments,jobs,state-budget,state-fi...  \n",
       "3256           cap-and-trade,climate-change,environment  \n",
       "4386                                              trade  \n",
       "4839                   economy,job-accomplishments,jobs  \n",
       "4940                                congressional-rules  \n",
       "6759                             human-rights,terrorism  \n",
       "6784                                              trade  \n",
       "7248                                        immigration  \n",
       "7647                congress,legal-issues,supreme-court  \n",
       "8906                      abortion,message-machine-2012  \n",
       "9400                                               jobs  \n",
       "9642                                congressional-rules  \n",
       "9750                               corporations,economy  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.duplicated(['Text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates(['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>4</td>\n",
       "      <td>Nobody is leaving Memphis. Thats a myth.</td>\n",
       "      <td>census,population,taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>2</td>\n",
       "      <td>Says black women are fastest-growing demograph...</td>\n",
       "      <td>guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>5</td>\n",
       "      <td>Ken Buck wants to outlaw abortion, even in cas...</td>\n",
       "      <td>abortion,message-machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                               Text  \\\n",
       "1767       4           Nobody is leaving Memphis. Thats a myth.   \n",
       "3299       2  Says black women are fastest-growing demograph...   \n",
       "4179       5  Ken Buck wants to outlaw abortion, even in cas...   \n",
       "\n",
       "                      Text_Tag  \n",
       "1767   census,population,taxes  \n",
       "3299                      guns  \n",
       "4179  abortion,message-machine  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into Train and Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['NewsText'] = train_data['Text_Tag'].astype(str) +\" \"+ train_data['Text']\n",
    "test_data['NewsText'] = test_data['Text_Tag'].astype(str) +\" \"+ test_data['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer object\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "class DataPreprocess:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.filters = [strip_tags,\n",
    "                       strip_numeric,\n",
    "                       strip_punctuation,\n",
    "                       lambda x: x.lower(),\n",
    "                       lambda x: re.sub(r'\\s+\\w{1}\\s+', '', x),\n",
    "                       remove_stopwords]\n",
    "    def __call__(self, doc):\n",
    "        clean_words = self.__apply_filter(doc)\n",
    "        return clean_words\n",
    "    \n",
    "    def __apply_filter(self, doc):\n",
    "        try:\n",
    "            cleanse_words = set(preprocess_string(doc, self.filters))\n",
    "            filtered_words = set(wnl.lemmatize(w, 'v') for w in cleanse_words)\n",
    "            return ' '.join(cleanse_words)\n",
    "        except TypeError as te:\n",
    "            raise(TypeError(\"Not a valid data {}\".format(te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Processed'] = train_data['NewsText'].apply(DataPreprocess())\n",
    "test_data['Processed'] = test_data['NewsText'].apply(DataPreprocess())\n",
    "\n",
    "# train_data['Processed'] = train_data['Text'].apply(DataPreprocess())\n",
    "# test_data['Processed'] = test_data['Text'].apply(DataPreprocess())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mexico border literally years immigration buil...\n",
       "1          jobs number year double layoffs pace wisconsin\n",
       "2       veterans vets help voting john says record mcc...\n",
       "3       advertising suzanne seniors choice advantage m...\n",
       "4       advertising hes ofcriminal gov scott laws fina...\n",
       "                              ...                        \n",
       "1262    level history highest funding state provides s...\n",
       "1263          justice rights civil ive day criminal crime\n",
       "1264    position earlysen disarmament reagan help edwa...\n",
       "1265    permit government new got strickland director ...\n",
       "1266    taxes fund going income governor finances earn...\n",
       "Name: Processed, Length: 1267, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (6849,), Holdout shape: (3374,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data['Processed']\n",
    "y = train_data['Labels']\n",
    "\n",
    "y_category = keras.utils.to_categorical(y, 6)\n",
    "\n",
    "# Split data into Train and Holdout as 80:20 ratio\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_category, shuffle=True, test_size=0.33, random_state=111)\n",
    "\n",
    "print(\"Train shape : {}, Holdout shape: {}\".format(X_train.shape, X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(train, test, max_features, max_len=200):\n",
    "    try:\n",
    "        # Keras Tokenizer class object\n",
    "        tokenizer = text.Tokenizer(num_words=max_features)\n",
    "        tokenizer.fit_on_texts(train)\n",
    "        \n",
    "        train_data = tokenizer.texts_to_sequences(train)\n",
    "        test_data = tokenizer.texts_to_sequences(test)\n",
    "        \n",
    "        # Get the max_len\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "        \n",
    "        # Padd the sequence based on the max-length\n",
    "        x_train = sequence.pad_sequences(train_data, maxlen=max_len, padding='post')\n",
    "        x_test = sequence.pad_sequences(test_data, maxlen=max_len, padding='post')\n",
    "        # Return train, test and vocab size\n",
    "        return tokenizer, x_train, x_test, vocab_size\n",
    "    except ValueError as ve:\n",
    "        raise(ValueError(\"Error in word embedding {}\".format(ve)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "max_len = 128\n",
    "output_dim = len(np.unique(y))\n",
    "\n",
    "# Test data\n",
    "X_test = test_data['Processed']\n",
    "\n",
    "tokenizer, x_pad_train, x_pad_valid, vocab_size = word_embedding(X_train, X_valid, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "X_test = test_data['Processed']\n",
    "\n",
    "tokenizer.fit_on_sequences(X_test)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "x_pad_test = sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classweights(target):\n",
    "    \"\"\"\n",
    "    Computes the weights of the target values based on the samples\n",
    "    :param target: Y-target variable\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "    # compute class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(target),\n",
    "                                                     target)\n",
    "    \n",
    "    # make the class weight list into dictionary\n",
    "    weights = {}\n",
    "    \n",
    "    # enumerate the list\n",
    "    for index, weight in enumerate(class_weights):\n",
    "        weights[index] = weight\n",
    "        \n",
    "    return weights\n",
    "\n",
    "# Get the class weights for the target variable\n",
    "weights = compute_classweights(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0307521677757612,\n",
       " 1: 0.8574903539674551,\n",
       " 2: 0.8078868342026236,\n",
       " 3: 0.868859425463199,\n",
       " 4: 2.0307906237584428,\n",
       " 5: 1.017821585025886}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3960    taxes new funding state sent floridians billio...\n",
       "6085    tens texas voters rick perrys wendy defeat law...\n",
       "6655    voted baldwin candidate extreme increase budge...\n",
       "Name: Processed, dtype: object"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn(vocab_size, output_dim, max_len):\n",
    "    # Building RNN model\n",
    "    model = Sequential([\n",
    "        keras.layers.Embedding(vocab_size,128,\n",
    "                              input_length=max_len),\n",
    "        keras.layers.BatchNormalization(),\n",
    "#         keras.layers.Bidirectional(keras.layers.LSTM(128,return_sequences=True)),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.002)),\n",
    "        keras.layers.GlobalMaxPool1D(), # Remove flatten layer\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.002)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.002)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 128, 128)          1515520   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 128, 128)          512       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 128, 128)          16512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_24 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 1,543,078\n",
      "Trainable params: 1,542,822\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = build_rnn(vocab_size, output_dim, max_len)\n",
    "\n",
    "# Summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), \n",
    "                  loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                  metrics=[tf.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 2.2825 - auc_29: 0.4780 - val_loss: 2.2350 - val_auc_29: 0.4785\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 2.1977 - auc_29: 0.5346 - val_loss: 2.1701 - val_auc_29: 0.5168\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 2.1246 - auc_29: 0.5849 - val_loss: 2.1146 - val_auc_29: 0.5480\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 2.0554 - auc_29: 0.6176 - val_loss: 2.0714 - val_auc_29: 0.5562\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 1.9910 - auc_29: 0.6624 - val_loss: 2.0377 - val_auc_29: 0.5565\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.9194 - auc_29: 0.7001 - val_loss: 2.0130 - val_auc_29: 0.5636\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.8560 - auc_29: 0.7401 - val_loss: 1.9953 - val_auc_29: 0.5627\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 1.7867 - auc_29: 0.7808 - val_loss: 1.9821 - val_auc_29: 0.5729\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.7134 - auc_29: 0.8230 - val_loss: 1.9731 - val_auc_29: 0.5707\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.6528 - auc_29: 0.8517 - val_loss: 1.9666 - val_auc_29: 0.5693\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 1.5954 - auc_29: 0.8770 - val_loss: 1.9604 - val_auc_29: 0.5792\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 1.5475 - auc_29: 0.8965 - val_loss: 1.9553 - val_auc_29: 0.5816\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.5043 - auc_29: 0.9118 - val_loss: 1.9523 - val_auc_29: 0.5705\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.4662 - auc_29: 0.9211 - val_loss: 1.9479 - val_auc_29: 0.5763\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 1.4406 - auc_29: 0.9309 - val_loss: 1.9445 - val_auc_29: 0.5735\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.4158 - auc_29: 0.9352 - val_loss: 1.9411 - val_auc_29: 0.5725\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 1.3916 - auc_29: 0.9427 - val_loss: 1.9378 - val_auc_29: 0.5699\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 1.3690 - auc_29: 0.9470 - val_loss: 1.9337 - val_auc_29: 0.5702\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 1.3553 - auc_29: 0.9502 - val_loss: 1.9285 - val_auc_29: 0.5761\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 1.3436 - auc_29: 0.9524 - val_loss: 1.9256 - val_auc_29: 0.5748\n"
     ]
    }
   ],
   "source": [
    "history = rnn_model.fit(x_pad_train, \n",
    "                        y_train,\n",
    "                        batch_size=512,\n",
    "                        epochs=20,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_pad_valid, y_valid),\n",
    "                       class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 4ms/step - loss: 1.9256 - auc_29: 0.5748\n"
     ]
    }
   ],
   "source": [
    "results = rnn_model.evaluate(x_pad_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = rnn_model.predict_proba(x_pad_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10799249, 0.10470885, 0.20419715, ..., 0.11288042, 0.07156285,\n",
       "       0.0953638 ], dtype=float32)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({'0': y_preds[:,0],\n",
    "                        '1': y_preds[:,1],\n",
    "                        '2': y_preds[:,2],\n",
    "                        '3': y_preds[:,3],\n",
    "                        '4': y_preds[:,4],\n",
    "                        '5': y_preds[:,5]}, index=test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107992</td>\n",
       "      <td>0.101322</td>\n",
       "      <td>0.150519</td>\n",
       "      <td>0.378211</td>\n",
       "      <td>0.134148</td>\n",
       "      <td>0.127807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104709</td>\n",
       "      <td>0.158395</td>\n",
       "      <td>0.332498</td>\n",
       "      <td>0.163373</td>\n",
       "      <td>0.189925</td>\n",
       "      <td>0.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.204197</td>\n",
       "      <td>0.133102</td>\n",
       "      <td>0.249838</td>\n",
       "      <td>0.167857</td>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.101418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167783</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>0.100499</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>0.130143</td>\n",
       "      <td>0.187575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.174848</td>\n",
       "      <td>0.282983</td>\n",
       "      <td>0.110808</td>\n",
       "      <td>0.102282</td>\n",
       "      <td>0.210029</td>\n",
       "      <td>0.119051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.097854</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>0.338114</td>\n",
       "      <td>0.165196</td>\n",
       "      <td>0.189197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0.142004</td>\n",
       "      <td>0.104889</td>\n",
       "      <td>0.095647</td>\n",
       "      <td>0.265502</td>\n",
       "      <td>0.085052</td>\n",
       "      <td>0.306905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>0.112880</td>\n",
       "      <td>0.168333</td>\n",
       "      <td>0.251629</td>\n",
       "      <td>0.280145</td>\n",
       "      <td>0.070717</td>\n",
       "      <td>0.116296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.071563</td>\n",
       "      <td>0.260155</td>\n",
       "      <td>0.113663</td>\n",
       "      <td>0.235579</td>\n",
       "      <td>0.170863</td>\n",
       "      <td>0.148177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0.095364</td>\n",
       "      <td>0.361185</td>\n",
       "      <td>0.258039</td>\n",
       "      <td>0.103341</td>\n",
       "      <td>0.052368</td>\n",
       "      <td>0.129703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5\n",
       "0     0.107992  0.101322  0.150519  0.378211  0.134148  0.127807\n",
       "1     0.104709  0.158395  0.332498  0.163373  0.189925  0.051100\n",
       "2     0.204197  0.133102  0.249838  0.167857  0.143589  0.101418\n",
       "3     0.167783  0.325967  0.100499  0.088033  0.130143  0.187575\n",
       "4     0.174848  0.282983  0.110808  0.102282  0.210029  0.119051\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "1262  0.125772  0.097854  0.083867  0.338114  0.165196  0.189197\n",
       "1263  0.142004  0.104889  0.095647  0.265502  0.085052  0.306905\n",
       "1264  0.112880  0.168333  0.251629  0.280145  0.070717  0.116296\n",
       "1265  0.071563  0.260155  0.113663  0.235579  0.170863  0.148177\n",
       "1266  0.095364  0.361185  0.258039  0.103341  0.052368  0.129703\n",
       "\n",
       "[1267 rows x 6 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"fake_news_ann_08.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
